{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:35:38.347857Z",
     "start_time": "2025-08-01T13:35:38.345349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fixed RandomSeed & Setting Hyperparameter"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:35:40.124044Z",
     "start_time": "2025-08-01T13:35:40.118286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:35:41.793055Z",
     "start_time": "2025-08-01T13:35:41.790759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Load"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:35:45.954070Z",
     "start_time": "2025-08-01T13:35:45.918630Z"
    }
   },
   "cell_type": "code",
   "source": "train = pd.read_csv(\"./dataset/train/train.csv\")",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:35:54.893345Z",
     "start_time": "2025-08-01T13:35:54.890237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiOutputLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, output_dim=7):\n",
    "        super(MultiOutputLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])  # (B, output_dim)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:36:02.211440Z",
     "start_time": "2025-08-01T13:36:02.205571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_lstm(train_df):\n",
    "    trained_models = {}\n",
    "\n",
    "    for store_menu, group in tqdm(train_df.groupby(['영업장명_메뉴명']), desc ='Training LSTM'):\n",
    "        store_train = group.sort_values('영업일자').copy()\n",
    "        if len(store_train) < LOOKBACK + PREDICT:\n",
    "            continue\n",
    "\n",
    "        features = ['매출수량']\n",
    "        scaler = MinMaxScaler()\n",
    "        store_train[features] = scaler.fit_transform(store_train[features])\n",
    "        train_vals = store_train[features].values  # shape: (N, 1)\n",
    "\n",
    "        # 시퀀스 구성\n",
    "        X_train, y_train = [], []\n",
    "        for i in range(len(train_vals) - LOOKBACK - PREDICT + 1):\n",
    "            X_train.append(train_vals[i:i+LOOKBACK])\n",
    "            y_train.append(train_vals[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        X_train = torch.tensor(X_train).float().to(DEVICE)\n",
    "        y_train = torch.tensor(y_train).float().to(DEVICE)\n",
    "\n",
    "        model = MultiOutputLSTM(input_dim=1, output_dim=PREDICT).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(EPOCHS):\n",
    "            idx = torch.randperm(len(X_train))\n",
    "            for i in range(0, len(X_train), BATCH_SIZE):\n",
    "                batch_idx = idx[i:i+BATCH_SIZE]\n",
    "                X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
    "                output = model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        trained_models[store_menu] = {\n",
    "            'model': model.eval(),\n",
    "            'scaler': scaler,\n",
    "            'last_sequence': train_vals[-LOOKBACK:]  # (28, 1)\n",
    "        }\n",
    "\n",
    "    return trained_models"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:36:48.573575Z",
     "start_time": "2025-08-01T13:36:04.106824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 학습\n",
    "trained_models = train_lstm(train)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LSTM: 100%|██████████| 193/193 [00:44<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prediction"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:36:50.842508Z",
     "start_time": "2025-08-01T13:36:50.837464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_lstm(test_df, trained_models, test_prefix: str):\n",
    "    results = []\n",
    "\n",
    "    for (store_menu,), store_test in test_df.groupby(['영업장명_메뉴명']):\n",
    "        key = store_menu\n",
    "        if key not in trained_models:\n",
    "            continue\n",
    "\n",
    "        model = trained_models[key]['model']\n",
    "        scaler = trained_models[key]['scaler']\n",
    "\n",
    "        store_test_sorted = store_test.sort_values('영업일자')\n",
    "        recent_vals = store_test_sorted['매출수량'].values[-LOOKBACK:]\n",
    "        if len(recent_vals) < LOOKBACK:\n",
    "            continue\n",
    "\n",
    "        recent_vals_df = pd.DataFrame(recent_vals, columns=['매출수량'])\n",
    "        recent_vals_scaled = scaler.transform(recent_vals_df)\n",
    "        x_input = torch.tensor([recent_vals_scaled]).float().to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = model(x_input).squeeze().cpu().numpy()\n",
    "\n",
    "        pred_scaled_reshaped = pred_scaled.reshape(-1, 1)\n",
    "        restored_pred = scaler.inverse_transform(pred_scaled_reshaped)\n",
    "        restored = np.round(np.maximum(0, restored_pred)).astype(int).flatten()\n",
    "\n",
    "        # 예측일자: TEST_00+1일 ~ TEST_00+7일\n",
    "        pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
    "\n",
    "        for d, val in zip(pred_dates, restored):\n",
    "            results.append({\n",
    "                '영업일자': d,\n",
    "                '영업장명_메뉴명': store_menu,\n",
    "                '매출수량': val\n",
    "            })\n",
    "    print(f\"{store_menu} recent input:\", recent_vals.flatten())\n",
    "    print(f\"{store_menu} scaled input:\", recent_vals_scaled.flatten())\n",
    "    print(f\"{store_menu} prediction result:\", pred_scaled)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:36:56.936445Z",
     "start_time": "2025-08-01T13:36:54.512323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_preds = []\n",
    "\n",
    "# 모든 test_*.csv 순회\n",
    "test_files = sorted(glob.glob('./dataset/test/TEST_*.csv'))\n",
    "\n",
    "for path in test_files:\n",
    "    test_df = pd.read_csv(path)\n",
    "\n",
    "    # 파일명에서 접두어 추출 (예: TEST_00)\n",
    "    filename = os.path.basename(path)\n",
    "    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n",
    "\n",
    "    pred_df = predict_lstm(test_df, trained_models, test_prefix)\n",
    "    all_preds.append(pred_df)\n",
    "    \n",
    "full_pred_df = pd.concat(all_preds, ignore_index=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53733/1817950123.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  x_input = torch.tensor([recent_vals_scaled]).float().to(DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "화담숲카페_현미뻥스크림 recent input: [60  0  8 28 21 20 15 63  0 13 14 12 18 56 18  0  0  2  8 11 18 12  0  4\n",
      "  4  7 10 41]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0.29126214 0.         0.03883495 0.13592233 0.10194175 0.09708738\n",
      " 0.07281553 0.30582524 0.         0.0631068  0.06796117 0.05825243\n",
      " 0.08737864 0.27184466 0.08737864 0.         0.         0.00970874\n",
      " 0.03883495 0.05339806 0.08737864 0.05825243 0.         0.01941748\n",
      " 0.01941748 0.03398058 0.04854369 0.19902913]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.06731705 0.08232439 0.08818489 0.0690828  0.08302604 0.07214014\n",
      " 0.08453845]\n",
      "화담숲카페_현미뻥스크림 recent input: [44  0  4  2 14 20 15 38  0 40 25 33 25 21 18  0 15  8  6 16 25 19  0 25\n",
      " 10 29 31 30]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0.21359223 0.         0.01941748 0.00970874 0.06796117 0.09708738\n",
      " 0.07281553 0.18446602 0.         0.19417476 0.12135922 0.16019417\n",
      " 0.12135922 0.10194175 0.08737864 0.         0.07281553 0.03883495\n",
      " 0.02912621 0.0776699  0.12135922 0.09223301 0.         0.12135922\n",
      " 0.04854369 0.1407767  0.15048544 0.14563107]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.10312983 0.11579215 0.12198128 0.10186405 0.11588734 0.10300957\n",
      " 0.11454675]\n",
      "화담숲카페_현미뻥스크림 recent input: [ 23   0   5   3  11   4  51  48   0  16   9  11  16  83  46   0  10   3\n",
      "   1   4  58 121 130  93  50  20   2  21]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0.11165049 0.         0.02427184 0.01456311 0.05339806 0.01941748\n",
      " 0.24757282 0.23300971 0.         0.0776699  0.04368932 0.05339806\n",
      " 0.0776699  0.40291262 0.22330097 0.         0.04854369 0.01456311\n",
      " 0.00485437 0.01941748 0.2815534  0.58737864 0.63106796 0.45145631\n",
      " 0.24271845 0.09708738 0.00970874 0.10194175]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.2201792  0.23887578 0.23480292 0.20818585 0.2235361  0.21125539\n",
      " 0.22325772]\n",
      "화담숲카페_현미뻥스크림 recent input: [221   0 141  79 234 214 212  64   0  18 281 102 115 196 152   0  88 125\n",
      " 129  55 188 148 123  54  91 179 239 297]\n",
      "화담숲카페_현미뻥스크림 scaled input: [1.07281553 0.         0.68446602 0.38349515 1.13592233 1.03883495\n",
      " 1.02912621 0.31067961 0.         0.08737864 1.36407767 0.49514563\n",
      " 0.55825243 0.95145631 0.73786408 0.         0.42718447 0.60679612\n",
      " 0.62621359 0.26699029 0.91262136 0.7184466  0.59708738 0.26213592\n",
      " 0.44174757 0.86893204 1.16019417 1.44174757]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.5337596  0.55589753 0.52772826 0.5105328  0.5478478  0.4740283\n",
      " 0.47258365]\n",
      "화담숲카페_현미뻥스크림 recent input: [246 122 113  75 132 184 200 194 185 115 126 125 156 229  75   0  53  38\n",
      "  34  37  79 121   0   0   0   0   0   0]\n",
      "화담숲카페_현미뻥스크림 scaled input: [1.19417476 0.59223301 0.54854369 0.36407767 0.6407767  0.89320388\n",
      " 0.97087379 0.94174757 0.89805825 0.55825243 0.61165049 0.60679612\n",
      " 0.75728155 1.11165049 0.36407767 0.         0.25728155 0.18446602\n",
      " 0.16504854 0.17961165 0.38349515 0.58737864 0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.13669093 0.16125068 0.151752   0.1227553  0.13809119 0.13962786\n",
      " 0.15539798]\n",
      "화담숲카페_현미뻥스크림 recent input: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.02490006 0.04413136 0.05035317 0.03229024 0.04588103 0.03704315\n",
      " 0.05022056]\n",
      "화담숲카페_현미뻥스크림 recent input: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.02490006 0.04413136 0.05035317 0.03229024 0.04588103 0.03704315\n",
      " 0.05022056]\n",
      "화담숲카페_현미뻥스크림 recent input: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.02490006 0.04413136 0.05035317 0.03229024 0.04588103 0.03704315\n",
      " 0.05022056]\n",
      "화담숲카페_현미뻥스크림 recent input: [  0   0   0   0   0  21  48  34   0  42  14  44  93  19 148   0  81  84\n",
      " 106 114 104  41   4  54  71  87  75  43]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0.         0.         0.         0.         0.         0.10194175\n",
      " 0.23300971 0.16504854 0.         0.2038835  0.06796117 0.21359223\n",
      " 0.45145631 0.09223301 0.7184466  0.         0.39320388 0.40776699\n",
      " 0.51456311 0.55339806 0.50485437 0.19902913 0.01941748 0.26213592\n",
      " 0.34466019 0.4223301  0.36407767 0.20873786]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.28588098 0.3000883  0.2918915  0.2676232  0.28500518 0.2659662\n",
      " 0.2757721 ]\n",
      "화담숲카페_현미뻥스크림 recent input: [118   0  39  48  10  66  26 137  37  62  14  22   0  18  67   0  22  13\n",
      "  11   9  69  80   0  16  50  15  22  22]\n",
      "화담숲카페_현미뻥스크림 scaled input: [0.57281553 0.         0.18932039 0.23300971 0.04854369 0.32038835\n",
      " 0.12621359 0.66504854 0.17961165 0.30097087 0.06796117 0.10679612\n",
      " 0.         0.08737864 0.32524272 0.         0.10679612 0.0631068\n",
      " 0.05339806 0.04368932 0.33495146 0.38834951 0.         0.0776699\n",
      " 0.24271845 0.07281553 0.10679612 0.10679612]\n",
      "화담숲카페_현미뻥스크림 prediction result: [0.14106405 0.15658611 0.1579512  0.13431655 0.14894831 0.13878204\n",
      " 0.15109324]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Submission"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:37:00.354505Z",
     "start_time": "2025-08-01T13:37:00.351077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
    "    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n",
    "    pred_dict = dict(zip(\n",
    "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
    "        pred_df['매출수량']\n",
    "    ))\n",
    "\n",
    "    final_df = sample_submission.copy()\n",
    "\n",
    "    for row_idx in final_df.index:\n",
    "        date = final_df.loc[row_idx, '영업일자']\n",
    "        for col in final_df.columns[1:]:  # 메뉴명들\n",
    "            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n",
    "\n",
    "    return final_df"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:37:05.805718Z",
     "start_time": "2025-08-01T13:37:04.403277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_submission = pd.read_csv('./dataset/sample_submission.csv')\n",
    "print(\"컬럼 목록:\", full_pred_df.columns)\n",
    "print(full_pred_df.head())\n",
    "\n",
    "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
    "\n",
    "submission.to_csv('./results/baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼 목록: Index(['영업일자', '영업장명_메뉴명', '매출수량'], dtype='object')\n",
      "         영업일자            영업장명_메뉴명  매출수량\n",
      "0  TEST_00+1일  느티나무 셀프BBQ_1인 수저세트     6\n",
      "1  TEST_00+2일  느티나무 셀프BBQ_1인 수저세트     6\n",
      "2  TEST_00+3일  느티나무 셀프BBQ_1인 수저세트     6\n",
      "3  TEST_00+4일  느티나무 셀프BBQ_1인 수저세트     6\n",
      "4  TEST_00+5일  느티나무 셀프BBQ_1인 수저세트     5\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seohee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
