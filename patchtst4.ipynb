{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17aee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gluonts==0.14.4\n",
    "#!pip install 'gluonts[torch]'\n",
    "#!pip install --upgrade gluonts\n",
    "#!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79387a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import holidays\n",
    "from transformers import PatchTSTConfig, PatchTSTForPrediction, TrainingArguments, Trainer\n",
    "\n",
    "# ğŸ’¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë³€ê²½: tsfm_publicì˜ ë„êµ¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a178ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.patchtst.modeling_patchtst import PatchTSTForPrediction\n",
    "\n",
    "TARGET_CH = 0  # sales_log ì±„ë„ ì¸ë±ìŠ¤(ë³´í†µ 0)\n",
    "\n",
    "class PatchTSTSalesOnly(torch.nn.Module):\n",
    "    def __init__(self, base: PatchTSTForPrediction, target_ch: int = TARGET_CH):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.target_ch = target_ch\n",
    "        self.config = base.config  # HFê°€ ì°¸ì¡°\n",
    "\n",
    "    # â˜… Trainerê°€ state_dict ì €ì¥í•  ë•Œ baseë§Œ ì €ì¥ë˜ë„ë¡\n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        return self.base.state_dict(*args, **kwargs)\n",
    "\n",
    "    # â˜… ë¡œë“œ ì‹œì—ë„ baseë¡œ ë¡œë“œë˜ë„ë¡\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        return self.base.load_state_dict(state_dict, strict)\n",
    "\n",
    "    # â˜… ëª…ì‹œì ìœ¼ë¡œ HuggingFace í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  ì‹¶ì„ ë•Œ\n",
    "    def save_pretrained(self, save_directory):\n",
    "        self.base.save_pretrained(save_directory)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_preds_from_output(out, pred_len: int, num_in_ch: int):\n",
    "        # dict-like\n",
    "        if hasattr(out, \"keys\"):\n",
    "            for k in [\"logits\", \"predictions\", \"prediction_outputs\", \"y_hat\", \"yhat\", \"forecast\"]:\n",
    "                v = out.get(k, None)\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    return v\n",
    "        # attribute\n",
    "        for k in [\"logits\", \"predictions\", \"prediction_outputs\", \"y_hat\", \"yhat\", \"forecast\"]:\n",
    "            v = getattr(out, k, None)\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                return v\n",
    "        # tuple/list\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            cand = [t for t in out if isinstance(t, torch.Tensor)]\n",
    "            for t in cand:\n",
    "                if t.ndim == 3 and t.shape[-2] == pred_len and (t.shape[-1] in (1, num_in_ch)):\n",
    "                    return t\n",
    "            for t in cand:\n",
    "                if t.ndim == 2 and t.shape[-1] == pred_len:\n",
    "                    return t\n",
    "            if cand:\n",
    "                return max(cand, key=lambda x: x.numel())\n",
    "        # fallback to tuple conversion\n",
    "        try:\n",
    "            tup = out.to_tuple()\n",
    "            for t in tup:\n",
    "                if isinstance(t, torch.Tensor) and t.ndim >= 2:\n",
    "                    return t\n",
    "        except Exception:\n",
    "            pass\n",
    "        raise AttributeError(\"ì˜ˆì¸¡ í…ì„œë¥¼ ì¶œë ¥ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def forward(self, past_values, past_observed_mask=None, future_values=None, **kwargs):\n",
    "        # ë‚´ë¶€ ê¸°ë³¸ lossëŠ” í”¼í•˜ê³  ì˜ˆì¸¡ë§Œ ì–»ê¸° ìœ„í•´ future_values=Noneìœ¼ë¡œ í˜¸ì¶œ\n",
    "        base_out = self.base(\n",
    "            past_values=past_values,\n",
    "            past_observed_mask=past_observed_mask,\n",
    "            future_values=None,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # ì˜ˆì¸¡ í…ì„œ ì¶”ì¶œ\n",
    "        preds_all = self._extract_preds_from_output(\n",
    "            base_out,\n",
    "            pred_len=self.config.prediction_length,\n",
    "            num_in_ch=self.config.num_input_channels,\n",
    "        )  # (B, pred_len, C) or (B, pred_len)\n",
    "\n",
    "        # íƒ€ê¹ƒ ì±„ë„ë§Œ ì„ íƒ\n",
    "        if preds_all.ndim == 3:\n",
    "            preds_target = preds_all[..., self.target_ch]  # (B, pred_len)\n",
    "        else:\n",
    "            preds_target = preds_all  # ì´ë¯¸ (B, pred_len)\n",
    "\n",
    "        # ë¼ë²¨ë„ íƒ€ê¹ƒ ì±„ë„ë§Œìœ¼ë¡œ ë§ì¶°ì„œ ì†ì‹¤ ê³„ì‚°\n",
    "        loss = None\n",
    "        if future_values is not None:\n",
    "            fv = future_values\n",
    "            if fv.ndim == 3 and fv.shape[-1] == self.config.num_input_channels:\n",
    "                target = fv[..., self.target_ch].float()      # (B, pred_len)\n",
    "            elif fv.ndim == 3 and fv.shape[-1] == 1:\n",
    "                target = fv.squeeze(-1).float()               # (B, pred_len)\n",
    "            elif fv.ndim == 2:\n",
    "                target = fv.float()\n",
    "            else:\n",
    "                raise RuntimeError(f\"future_values shape ì˜ˆìƒ ë°–: {fv.shape}\")\n",
    "            loss = F.mse_loss(preds_target.float(), target)\n",
    "\n",
    "        # HF Trainerê°€ ì¸ì‹í•˜ëŠ” dict ë°˜í™˜ (loss/logits í•„ìˆ˜)\n",
    "        ret = {\n",
    "            \"logits\": preds_target,           # predict/evalì—ì„œ ì‚¬ìš©\n",
    "            \"predictions\": preds_target,      # predict() ì‹œ í¸ì˜\n",
    "        }\n",
    "        if loss is not None:\n",
    "            ret[\"loss\"] = loss\n",
    "        # í•„ìš”í•˜ë©´ loc/scaleë„ íŒ¨ìŠ¤ìŠ¤ë£¨\n",
    "        for k in [\"loc\", \"scale\"]:\n",
    "            v = getattr(base_out, k, None) if not isinstance(base_out, dict) else base_out.get(k, None)\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                ret[k] = v\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fdbd2",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f2ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œì‹œì¼ì—ë§Œ ìˆëŠ” ë©”ë‰´: set()\n",
      "íŒë§¤ ë°ì´í„°ì—ë§Œ ìˆëŠ” ë©”ë‰´: {'ë¼ê·¸ë¡œíƒ€_ì¹´ìŠ¤', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì”ë””ê·¸ëŠ˜ì§‘ ëŒ€ì—¬ë£Œ (6ì¸ì„)', 'ë‹´í•˜_ì½œë¼', 'ì—°íšŒì¥_Cass Beer', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì”ë””ê·¸ëŠ˜ì§‘ ì˜ì ì¶”ê°€', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸', 'ì¹´í˜í…Œë¦¬ì•„_ì•„ë©”ë¦¬ì¹´ë…¸(ICE)', 'ì—°íšŒì¥_Convention Hall', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì¼íšŒìš© ì¢…ì´ì»µ', 'ì—°íšŒì¥_Grand Ballroom', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ë³µìˆ­ì•„ ì•„ì´ìŠ¤í‹°', 'í™”ë‹´ìˆ²ì¹´í˜_ì•„ë©”ë¦¬ì¹´ë…¸ HOT', 'ë‹´í•˜_ì œë¡œì½œë¼', 'í™”ë‹´ìˆ²ì£¼ë§‰_ì°¸ì‚´ì´ ë§‰ê±¸ë¦¬', 'ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜(ëŒ€ì¸) ì£¼ì¤‘', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì”ë””ê·¸ëŠ˜ì§‘ ëŒ€ì—¬ë£Œ (12ì¸ì„)', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì¹œí™˜ê²½ ì ‘ì‹œ 23cm', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì¼íšŒìš© ì†Œì£¼ì»µ', 'ë¯¸ë¼ì‹œì•„_ê³µê¹ƒë°¥', 'ë¯¸ë¼ì‹œì•„_ì˜¤ë¸êµ¬ì´ ìœ™ê³¼ í‚¬ë°”ì‚¬ì†Œì„¸ì§€', 'ì—°íšŒì¥_ë¡œì œ ì¹˜ì¦ˆë–¡ë³¶ì´', 'ì¹´í˜í…Œë¦¬ì•„_ì¹´í˜ë¼ë–¼(ICE)', 'ë¯¸ë¼ì‹œì•„_BBQ Platter', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì¹˜ì¦ˆ í•«ë„ê·¸', 'í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ìŠ¤í”„ë¼ì´íŠ¸', 'ì¹´í˜í…Œë¦¬ì•„_ì§œì¥ë°¥', 'ë¼ê·¸ë¡œíƒ€_Gls.ë¯¸ì…˜ ì„œë“œ', 'ë¼ê·¸ë¡œíƒ€_ì•„ë©”ë¦¬ì¹´ë…¸', 'ë¼ê·¸ë¡œíƒ€_ìŠ¤í”„ë¼ì´íŠ¸', 'ì¹´í˜í…Œë¦¬ì•„_ì•„ë©”ë¦¬ì¹´ë…¸(HOT)', 'ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜ 2ì¸ íŒ¨í‚¤ì§€ ', 'ë¯¸ë¼ì‹œì•„_(í™”ë•) ë¶ˆê³ ê¸° í˜í¼ë¡œë‹ˆ ë°˜ë°˜í”¼ì', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì‹ ë¼ë©´', 'ì¹´í˜í…Œë¦¬ì•„_ì•½ ê³ ì¶”ì¥ ëŒì†¥ë¹„ë¹”ë°¥', 'ë¼ê·¸ë¡œíƒ€_ë¹µ ì¶”ê°€ (1ì¸)', 'ë‹´í•˜_ìŠ¤í”„ë¼ì´íŠ¸', 'í™”ë‹´ìˆ²ì¹´í˜_ë©”ë°€ë¯¸ìˆ«ê°€ë£¨', 'ì—°íšŒì¥_ëª¨ë‘  ëˆìœ¡êµ¬ì´(3ì¸)', 'ë‹´í•˜_ì²˜ìŒì²˜ëŸ¼', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 30,000ì›', 'ë¯¸ë¼ì‹œì•„_(ë‹¨ì²´)ë¸ŒëŸ°ì¹˜ì£¼ì¤‘ 36,000', 'í™”ë‹´ìˆ²ì£¼ë§‰_ë‹¨í˜¸ë°• ì‹í˜œ ', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì•„ë©”ë¦¬ì¹´ë…¸(HOT)', 'ì¹´í˜í…Œë¦¬ì•„_ë³µìˆ­ì•„ ì•„ì´ìŠ¤í‹°', 'ë¯¸ë¼ì‹œì•„_BBQ ê³ ê¸°ì¶”ê°€', 'ë‹´í•˜_ë‹´í•˜ í•œìš° ë¶ˆê³ ê¸°', 'ì—°íšŒì¥_Conference M9', 'ë¼ê·¸ë¡œíƒ€_Open Food', 'ì—°íšŒì¥_ê³¨ë±…ì´ë¬´ì¹¨', 'ë‹´í•˜_ì¹´ìŠ¤', 'ì¹´í˜í…Œë¦¬ì•„_ìƒ· ì¶”ê°€', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_BBQ55(ë‹¨ì²´)', 'ì¹´í˜í…Œë¦¬ì•„_ì§¬ë½•', 'ì—°íšŒì¥_Conference L1', 'í™”ë‹´ìˆ²ì¹´í˜_ì¹´í˜ë¼ë–¼ ICE', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì°¸ì´ìŠ¬ (ë‹¨ì²´)', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì•„ë©”ë¦¬ì¹´ë…¸(ICE)', 'ë‹´í•˜_í•œìš° ìš°ê±°ì§€ êµ­ë°¥', 'í™”ë‹´ìˆ²ì£¼ë§‰_ë³‘ì²œìˆœëŒ€', 'ë¼ê·¸ë¡œíƒ€_G-Charge(3)', 'ì—°íšŒì¥_Regular Coffee', 'ë‹´í•˜_(ë‹¨ì²´) í™©íƒœí•´ì¥êµ­ 3/27ê¹Œì§€', 'ë¯¸ë¼ì‹œì•„_ì–¼ê·¸ë ˆì´ í•˜ì´ë³¼', 'ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜ 4ì¸ íŒ¨í‚¤ì§€ ', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì¹´ìŠ¤ ë³‘(ë‹¨ì²´)', 'ì¹´í˜í…Œë¦¬ì•„_êµ¬ìŠ¬ì•„ì´ìŠ¤í¬ë¦¼', 'ë‹´í•˜_ê°‘ì˜¤ì§•ì–´ ë¹„ë¹”ë°¥', 'ë‹´í•˜_ì€ì´ë²„ì„¯ ê°ˆë¹„íƒ•', 'ì¹´í˜í…Œë¦¬ì•„_ìƒˆìš° ë³¶ìŒë°¥', 'ì¹´í˜í…Œë¦¬ì•„_ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ', 'í™”ë‹´ìˆ²ì£¼ë§‰_ì½œë¼', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì¹´í˜ë¼ë–¼(HOT)', 'ì—°íšŒì¥_Conference M8', 'ë‹´í•˜_ë“¤ê¹¨ ì–‘ì§€íƒ•', 'ë¼ê·¸ë¡œíƒ€_Gls.Sileni', 'ë¯¸ë¼ì‹œì•„_ì• í”Œë§ê³  ì—ì´ë“œ', 'ë‹´í•˜_ìƒëª©ì‚´ ê¹€ì¹˜ì°Œê°œ', 'ë‹´í•˜_ê³µê¹ƒë°¥', 'ì—°íšŒì¥_Cookie Platter', 'ë‹´í•˜_ë©”ë°€ë©´ ì‚¬ë¦¬', 'ì—°íšŒì¥_Conference L3', 'ì—°íšŒì¥_Conference M1', 'ì—°íšŒì¥_ì•¼ì±„ì¶”ê°€', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_í˜ìŠ¤ì¸„ë¦¬ ì†Œì‹œì§€', 'ë¯¸ë¼ì‹œì•„_ë¯¸ë¼ì‹œì•„ ë¸ŒëŸ°ì¹˜ (íŒ¨í‚¤ì§€)', 'ë‹´í•˜_(ë‹¨ì²´) ê³µê¹ƒë°¥', 'ì¹´í˜í…Œë¦¬ì•„_ì˜¤í”ˆí‘¸ë“œ', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ìƒìˆ˜', 'ë¼ê·¸ë¡œíƒ€_í•˜ì´ë„¤ì¼„(ìƒ)', 'ì¹´í˜í…Œë¦¬ì•„_ì§¬ë½•ë°¥', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 90,000ì›', 'ì¹´í˜í…Œë¦¬ì•„_ê³µê¹ƒë°¥(ì¶”ê°€)', 'ë‹´í•˜_(ë‹¨ì²´) í•œìš° ìš°ê±°ì§€ êµ­ë°¥', 'ë‹´í•˜_í•œìš° ë–¡ê°ˆë¹„ ì •ì‹', 'ë¯¸ë¼ì‹œì•„_ë ˆì¸ë³´ìš°ì¹µí…Œì¼(ì•Œì½”ì˜¬)', 'ë‹´í•˜_í™©íƒœí•´ì¥êµ­', 'ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜(ì–´ë¦°ì´)', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŠ¤í”„ë¼ì´íŠ¸ (ë‹¨ì²´)', 'ë¯¸ë¼ì‹œì•„_ë¸ŒëŸ°ì¹˜(ëŒ€ì¸) ì£¼ë§', 'ì¹´í˜í…Œë¦¬ì•„_ìˆ˜ì œ ë“±ì‹¬ ëˆê¹ŒìŠ¤', 'ì—°íšŒì¥_ëˆëª©ì‚´ ê¹€ì¹˜ì°Œê°œ (ë°¥í¬í•¨)', 'ì¹´í˜í…Œë¦¬ì•„_ì–´ë¦°ì´ ëˆê¹ŒìŠ¤', 'ë‹´í•˜_í•œìš° ì°¨ëŒë°•ì´ ëœì¥ì°Œê°œ', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 60,000ì›', 'í™”ë‹´ìˆ²ì£¼ë§‰_í•´ë¬¼íŒŒì „', 'ì—°íšŒì¥_ì£¼ë¨¹ë°¥ (2ea)', 'ë‹´í•˜_ëŠë¦°ë§ˆì„ ë§‰ê±¸ë¦¬', 'ì¹´í˜í…Œë¦¬ì•„_ì¹˜ì¦ˆëˆê¹ŒìŠ¤', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì¹´í˜ë¼ë–¼(ICE)', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ë–¡ë³¶ì´', 'í™”ë‹´ìˆ²ì£¼ë§‰_ìŠ¤í”„ë¼ì´íŠ¸', 'ì¹´í˜í…Œë¦¬ì•„_í•œìƒ ì‚¼ê²¹êµ¬ì´ ì •ì‹(2ì¸) ì†Œìš”ì‹œê°„ ì•½ 15~20ë¶„', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ì½”ì¹´ì½œë¼', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ë³¸ì‚¼ê²¹ (ë‹¨í’ˆ,ì‹¤ë‚´)', 'ì—°íšŒì¥_Conference L2', 'ë¯¸ë¼ì‹œì•„_ê¸€ë¼ìŠ¤ì™€ì¸ (ë ˆë“œ)', 'ë‹´í•˜_ë£¸ ì´ìš©ë£Œ', 'í™”ë‹´ìˆ²ì£¼ë§‰_ëŠë¦°ë§ˆì„ ë§‰ê±¸ë¦¬', 'ë‹´í•˜_í…Œë¼', 'ë¼ê·¸ë¡œíƒ€_ìëª½ë¦¬ì¹˜ì—ì´ë“œ', 'ì—°íšŒì¥_ë§¤ì½¤ ë¬´ë¼ˆë‹­ë°œ&ê³„ë€ì°œ', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì¹œí™˜ê²½ ì ‘ì‹œ 14cm', 'ë¼ê·¸ë¡œíƒ€_ë¯¸ì…˜ ì„œë“œ ì¹´ë² ë¥´ë„¤ ì‰¬ë¼', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì•¼ì±„ì„¸íŠ¸', 'ì¹´í˜í…Œë¦¬ì•„_ì§œì¥ë©´', 'ë¼ê·¸ë¡œíƒ€_ì œë¡œì½œë¼', 'ì—°íšŒì¥_OPUS 2', 'í™”ë‹´ìˆ²ì¹´í˜_ì•„ë©”ë¦¬ì¹´ë…¸ ICE', 'í¬ë ˆìŠ¤íŠ¸ë¦¿_ê¼¬ì¹˜ì–´ë¬µ', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì½œë¼ (ë‹¨ì²´)', 'ë¼ê·¸ë¡œíƒ€_í•´ì‚°ë¬¼ í† ë§ˆí†  ìŠ¤íŒŒê²Œí‹°', 'ì¹´í˜í…Œë¦¬ì•„_ìƒˆìš°íŠ€ê¹€ ìš°ë™', 'ë¼ê·¸ë¡œíƒ€_ì½œë¼', 'ë‹´í•˜_ë¼ë©´ì‚¬ë¦¬', 'ë‹´í•˜_ì°¸ì´ìŠ¬', 'í™”ë‹´ìˆ²ì£¼ë§‰_ì°¹ìŒ€ì‹í˜œ', 'ë¼ê·¸ë¡œíƒ€_í•´ì‚°ë¬¼ í† ë§ˆí†  ë¦¬ì¡°ë˜', 'ë‹´í•˜_í•œìš° ë¯¸ì—­êµ­ ì •ì‹', 'ë‹´í•˜_(í›„ì‹) ëœì¥ì°Œê°œ', 'ì¹´í˜í…Œë¦¬ì•„_ì¹´í˜ë¼ë–¼(HOT)'}\n"
     ]
    }
   ],
   "source": [
    "# open_date.csvì˜ ë©”ë‰´ ì´ë¦„ ì§‘í•©\n",
    "launch_menu_names = set(pd.read_csv('./EDA/open_date.csv')['ë©”ë‰´'].dropna())\n",
    "\n",
    "# train.csvì˜ ë©”ë‰´ ì´ë¦„ ì§‘í•©\n",
    "sales_menu_names = set(pd.read_csv(\"./dataset/train/train.csv\")['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].dropna())\n",
    "\n",
    "# ì¶œì‹œì¼ì—ë§Œ ìˆê³  íŒë§¤ ë°ì´í„°ì—ëŠ” ì—†ëŠ” ë©”ë‰´ (ë¬¸ì œê°€ ë  ê°€ëŠ¥ì„±ì€ ì ìŒ)\n",
    "print(\"ì¶œì‹œì¼ì—ë§Œ ìˆëŠ” ë©”ë‰´:\", launch_menu_names - sales_menu_names)\n",
    "\n",
    "# íŒë§¤ ë°ì´í„°ì—ëŠ” ìˆëŠ”ë° ì¶œì‹œì¼ ì •ë³´ê°€ ì—†ëŠ” ë©”ë‰´ (ì´ ë¶€ë¶„ì„ í™•ì¸í•´ì•¼ í•¨)\n",
    "print(\"íŒë§¤ ë°ì´í„°ì—ë§Œ ìˆëŠ” ë©”ë‰´:\", sales_menu_names - launch_menu_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b84831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ. DataFrame ìƒ˜í”Œ:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1423/1688156681.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('store_menu').apply(mask_prelaunch_sales).reset_index(drop=True)\n",
      "/tmp/ipykernel_1423/1688156681.py:40: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df[\"is_holiday\"] = df[\"date\"].isin(kr_holidays).astype(int)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ë¼ê·¸ë¡œíƒ€_ê¹Œë¥´ë³´ë‚˜ë¼, ë‹´í•˜ ê¼¬ë§‰ ë¹„ë¹”ë°¥ì€ íŒë§¤ìˆ˜ëŸ‰ì´ 0ì´ì–´ë„ íŒë§¤í•˜ì§€ ì•ŠëŠ” ê¸°ê°„ê¹Œì§€ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‹œì‘ ì‹œì  ìˆ˜ì •í•¨\n",
    "'''\n",
    "# ==============================================\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì‚¬ìš©ì ì½”ë“œ ìœ ì§€)\n",
    "# ==============================================\n",
    "\n",
    "# 1. ì‹ ë©”ë‰´ ì¶œì‹œì¼ ë°ì´í„° ì¤€ë¹„\n",
    "menu_launch_df = pd.read_csv('./EDA/open_date.csv')\n",
    "menu_launch_df['ì¶œì‹œ'] = pd.to_datetime(menu_launch_df['ì¶œì‹œ'], errors='coerce')\n",
    "launch_dates = menu_launch_df.set_index('ë©”ë‰´')['ì¶œì‹œ'].dropna().to_dict()\n",
    "\n",
    "def mask_prelaunch_sales(group):\n",
    "    menu_name = group.name\n",
    "    launch_date = launch_dates.get(menu_name)\n",
    "    \n",
    "    if launch_date:\n",
    "        group.loc[group['date'] < launch_date, 'sales'] = np.nan\n",
    "    return group\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/train/train.csv\")\n",
    "df.columns = [\"date\", \"store_menu\", \"sales\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "df.loc[df['sales'] < 0, 'sales'] = 0\n",
    "df[\"sales\"] = df[\"sales\"].astype(float)\n",
    "# ë©”ë‰´ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í•¨ìˆ˜ ì ìš© í›„ ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "df = df.groupby('store_menu').apply(mask_prelaunch_sales).reset_index(drop=True)\n",
    "df[\"sales_log\"] = np.log1p(df[\"sales\"])     # targetì€ ì´ì œ sales_log\n",
    "\n",
    "# entity embeddingìš© ID ì¸ì½”ë”©\n",
    "# LabelEncoder ê°ì²´ë¥¼ ì €ì¥í•´ë‘ë©´ ë‚˜ì¤‘ì— ì›ë˜ ì´ë¦„ìœ¼ë¡œ ë³µì›í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "encoder = LabelEncoder()\n",
    "df[\"store_menu_id\"] = encoder.fit_transform(df[\"store_menu\"])\n",
    "num_entities = df[\"store_menu_id\"].nunique() # ê³ ìœ  ID ê°œìˆ˜ ì €ì¥\n",
    "\n",
    "# feature ì¶”ê°€\n",
    "kr_holidays = holidays.KR(years=df['date'].dt.year.unique())\n",
    "df[\"is_holiday\"] = df[\"date\"].isin(kr_holidays).astype(int)\n",
    "df[\"is_weekend\"] = df[\"date\"].dt.day_of_week.isin([5, 6]).astype(int)\n",
    "df[\"is_ski_season\"] = df[\"date\"].dt.month.isin([12, 1, 2]).astype(int)\n",
    "\n",
    "print(\"ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ. DataFrame ìƒ˜í”Œ:\")\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e560120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales\n",
       "False    93386\n",
       "True      9290\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sales\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38360b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_menu</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales_log</th>\n",
       "      <th>store_menu_id</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_ski_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     store_menu  sales  sales_log  store_menu_id  is_holiday  \\\n",
       "4788 2023-01-01  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    NaN        NaN              9           1   \n",
       "4789 2023-01-02  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    NaN        NaN              9           0   \n",
       "4790 2023-01-03  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    NaN        NaN              9           0   \n",
       "4791 2023-01-04  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    NaN        NaN              9           0   \n",
       "4792 2023-01-05  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    NaN        NaN              9           0   \n",
       "...         ...            ...    ...        ...            ...         ...   \n",
       "5315 2024-06-11  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    0.0   0.000000              9           0   \n",
       "5316 2024-06-12  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    0.0   0.000000              9           0   \n",
       "5317 2024-06-13  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    0.0   0.000000              9           0   \n",
       "5318 2024-06-14  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    2.0   1.098612              9           0   \n",
       "5319 2024-06-15  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥    2.0   1.098612              9           0   \n",
       "\n",
       "      is_weekend  is_ski_season  \n",
       "4788           1              1  \n",
       "4789           0              1  \n",
       "4790           0              1  \n",
       "4791           0              1  \n",
       "4792           0              1  \n",
       "...          ...            ...  \n",
       "5315           0              0  \n",
       "5316           0              0  \n",
       "5317           0              0  \n",
       "5318           0              0  \n",
       "5319           1              0  \n",
       "\n",
       "[532 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"store_menu\"] == \"ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba0ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ ë³€í™˜ ì™„ë£Œ âœ…\n",
      "train_dataset ê¸¸ì´: 93219\n",
      "valid_dataset ê¸¸ì´: 193\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. ForecastDFDatasetìœ¼ë¡œ ë³€í™˜\n",
    "# ==============================================\n",
    "forecast_horizon = 7\n",
    "context_length = 28\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
    "split_date = df['date'].max() - pd.Timedelta(days=forecast_horizon * 2)\n",
    "train_data = df[df['date'] < split_date]\n",
    "valid_data = df[df['date'] >= split_date]  # ê²€ì¦ ë°ì´í„°ëŠ” ì „ì²´ ì‚¬ìš©\n",
    "\n",
    "# ForecastDFDataset ìƒì„±\n",
    "train_dataset = ForecastDFDataset(\n",
    "    train_data,\n",
    "    id_columns=[\"store_menu_id\"],\n",
    "    timestamp_column=\"date\",\n",
    "    target_columns=[\"sales_log\"],\n",
    "    control_columns=[\"is_holiday\", \"is_weekend\", \"is_ski_season\"],\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "\n",
    "valid_dataset = ForecastDFDataset(\n",
    "    valid_data,\n",
    "    id_columns=[\"store_menu_id\"],\n",
    "    timestamp_column=\"date\",\n",
    "    target_columns=[\"sales_log\"],\n",
    "    control_columns=[\"is_holiday\", \"is_weekend\", \"is_ski_season\"],\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "\n",
    "print(\"ë°ì´í„°ì…‹ ë³€í™˜ ì™„ë£Œ âœ…\")\n",
    "print(\"train_dataset ê¸¸ì´:\", len(train_dataset))\n",
    "print(\"valid_dataset ê¸¸ì´:\", len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f05579",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ë° í•™ìŠµ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7cfdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. PatchTST ëª¨ë¸ ë° í•™ìŠµ ì„¤ì • (Hugging Face ì½”ë“œ)\n",
    "# ==============================================\n",
    "config = PatchTSTConfig(\n",
    "    # --- ë°ì´í„° ê´€ë ¨ ì„¤ì • ---\n",
    "    num_input_channels=4, # sales + 3 known covariates\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    "    # ğŸ’¡ ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” ì™¸ë¶€ ë³€ìˆ˜ì˜ ê°œìˆ˜\n",
    "    num_time_varying_known_reals=3, # is_holiday, is_weekend, is_ski_season\n",
    "\n",
    "    # --- Entity Embedding ê´€ë ¨ ì„¤ì • ---\n",
    "    # ğŸ’¡ ê³ ìœ  IDë¥¼ embedding í•˜ê¸° ìœ„í•œ ì„¤ì •\n",
    "    num_static_categorical_features=1, # store_menu_id 1ê°œ\n",
    "    cardinality=[num_entities],      # store_menu_idì˜ ê³ ìœ ê°’ ê°œìˆ˜\n",
    "    embedding_dimension=[32],        # store_menu_idë¥¼ 32ì°¨ì›ìœ¼ë¡œ ì„ë² ë”©\n",
    "\n",
    "    # --- ëª¨ë¸ êµ¬ì¡° ì„¤ì • ---\n",
    "    patch_length=8,\n",
    "    patch_stride=8,\n",
    "    d_model=128,\n",
    "    num_attention_heads=16,\n",
    "    num_hidden_layers=3,\n",
    "    ffn_dim=256,\n",
    "    dropout=0.2,\n",
    "    head_dropout=0.2,\n",
    "    scaling=\"std\",\n",
    "    loss=\"mse\",\n",
    ")\n",
    "\n",
    "#model = PatchTSTForPrediction(config)\n",
    "# ê¸°ì¡´ êµ¬ì„±\n",
    "base_model = PatchTSTForPrediction(config)\n",
    "\n",
    "# ë˜í•‘\n",
    "model = PatchTSTSalesOnly(base_model, target_ch=0)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./patchtst_sales_forecast\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=50, # ì˜ˆì‹œë¡œ ì—í­ ìˆ˜ ì¤„ì„\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    label_names=[\"future_values\"],\n",
    "    dataloader_pin_memory=True,\n",
    "    use_mps_device=False,\n",
    ")\n",
    "\n",
    "# ê·¸ëŒ€ë¡œ Hugging Face Trainer ì‚¬ìš©\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a716c1b",
   "metadata": {},
   "source": [
    "### Optuna\n",
    "\n",
    "- dashboard ì—¬ëŠ” ë²•\n",
    "\n",
    "optuna-dashboard sqlite:///./patchtst_sales_forecast/optuna.sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15d427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optuna Trial: Creating model with context=28, horizon=7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 16:53:49,993] A new study created in RDB with name: patchtst_sales_forecast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optuna Trial: Creating model with context=28, horizon=7 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5832' max='17496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5832/17496 03:22 < 06:46, 28.73 it/s, Epoch 6/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.947700</td>\n",
       "      <td>1.285069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>1.211609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>1.125430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>1.058608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>1.074715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>1.147705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 16:57:16,364] Trial 0 finished with value: 1.1477051973342896 and parameters: {'learning_rate': 4.533699953672491e-05, 'weight_decay': 0.054432313763740296, 'warmup_ratio': 0.12141502479504124, 'lr_scheduler_type': 'cosine_with_restarts', 'per_device_train_batch_size': 96, 'per_device_eval_batch_size': 32, 'num_train_epochs': 18, 'd_model': 128, 'num_attention_heads': 8, 'num_hidden_layers': 3, 'ffn_dim': 512, 'dropout': 0.21360807615127791, 'head_dropout': 0.02277571398798699, 'patch_length': 7}. Best is trial 0 with value: 1.1477051973342896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optuna Trial: Creating model with context=28, horizon=7 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8224' max='110732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8224/110732 04:17 < 53:28, 31.95 it/s, Epoch 2.82/38]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>1.197093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>0.987150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers.models.patchtst import PatchTSTConfig, PatchTSTForPrediction\n",
    "import os, optuna\n",
    "\n",
    "STUDY_NAME = \"patchtst_sales_forecast\"  # ì›í•˜ëŠ” ì´ë¦„ (ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ ì´ì–´ì§)\n",
    "STORAGE = f\"sqlite:///{os.path.abspath('./patchtst_sales_forecast/optuna.sqlite3')}\"\n",
    "\n",
    "# ---- 1) trial=None ì•ˆì „í•œ helper ----\n",
    "def s_cat(trial, name, choices, default):\n",
    "    return trial.suggest_categorical(name, choices) if trial else default\n",
    "\n",
    "def s_int(trial, name, low, high, default):\n",
    "    return trial.suggest_int(name, low, high) if trial else default\n",
    "\n",
    "def s_float(trial, name, low, high, default, log=False):\n",
    "    return trial.suggest_float(name, low, high, log=log) if trial else default\n",
    "\n",
    "\n",
    "# --- 1) ëª¨ë¸ ìƒì„± í•¨ìˆ˜: trialë¡œë¶€í„° ì•„í‚¤í…ì²˜/í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ì„œ ëª¨ë¸ êµ¬ì„± ---\n",
    "def model_init(trial):\n",
    "    # [ë””ë²„ê¹…] ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œë§ˆë‹¤ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    print(f\"--- Optuna Trial: Creating model with context={context_length}, horizon={forecast_horizon} ---\")\n",
    "    # â¬‡ï¸ ì•„í‚¤í…ì²˜ íƒìƒ‰ ê³µê°„ (í•„ìš”í•œ ê²ƒë§Œ ë‚¨ê¸°ê³ /ëŠ˜ë ¤ë„ ë¨)\n",
    "    d_model  = s_cat(trial, \"d_model\", [64, 128, 256], 128)\n",
    "    # d_modelë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ëŠ” headë§Œ í—ˆìš©\n",
    "    heads_cand = [h for h in [4, 8, 16] if d_model % h == 0]\n",
    "    num_heads = s_cat(trial, \"num_attention_heads\", heads_cand, heads_cand[0])\n",
    "    num_layers = s_int(trial, \"num_hidden_layers\", 2, 4, 3)\n",
    "    ffn_dim   = s_cat(trial, \"ffn_dim\", [128, 256, 512], 256)\n",
    "    dropout   = s_float(trial, \"dropout\", 0.0, 0.3, 0.2)\n",
    "    head_do   = s_float(trial, \"head_dropout\", 0.0, 0.3, 0.2)\n",
    "    patch_choices = [1, 7]\n",
    "    patch_len = s_cat(trial, \"patch_length\", patch_choices, 7)\n",
    "    patch_str = patch_len  # stride=length ê³ ì •\n",
    "\n",
    "    cfg = PatchTSTConfig(\n",
    "        # --- ê³ ì • (ë„¤ íŒŒì´í”„ë¼ì¸) ---\n",
    "        num_input_channels=4,\n",
    "        context_length=context_length,\n",
    "        prediction_length=forecast_horizon,\n",
    "        num_time_varying_known_reals=3,\n",
    "        num_static_categorical_features=1,\n",
    "        cardinality=[num_entities],\n",
    "        embedding_dimension=[32],\n",
    "        scaling=\"std\",\n",
    "        loss=\"mse\",\n",
    "        # --- íƒìƒ‰ ëŒ€ìƒ ---\n",
    "        d_model=d_model,\n",
    "        num_attention_heads=num_heads,\n",
    "        num_hidden_layers=num_layers,\n",
    "        ffn_dim=ffn_dim,\n",
    "        dropout=dropout,\n",
    "        head_dropout=head_do,\n",
    "        patch_length=patch_len,\n",
    "        patch_stride=patch_str,\n",
    "    )\n",
    "    import math\n",
    "    def _eff(L,p,s): return p * math.ceil(L / s)\n",
    "    def assert_no_padding(cfg):\n",
    "        ec = _eff(cfg.context_length, cfg.patch_length, cfg.patch_stride)\n",
    "        ep = _eff(cfg.prediction_length, cfg.patch_length, cfg.patch_stride)\n",
    "        if (ec, ep) != (cfg.context_length, cfg.prediction_length):\n",
    "            raise ValueError(f\"padding: ctx {cfg.context_length}->{ec}, pred {cfg.prediction_length}->{ep} \"\n",
    "                            f\"(p={cfg.patch_length}, s={cfg.patch_stride})\")\n",
    "    # model_init ë‚´ë¶€ì—ì„œ cfg ë§Œë“  ì§í›„ í˜¸ì¶œ\n",
    "    assert_no_padding(cfg)\n",
    "\n",
    "    base = PatchTSTForPrediction(cfg)\n",
    "    # sales ì±„ë„ë§Œ loss/ì˜ˆì¸¡í•˜ë„ë¡ ë§Œë“  ë˜í¼\n",
    "    return PatchTSTSalesOnly(base, target_ch=0)\n",
    "\n",
    "# --- 2) í•™ìŠµ ì„¸íŒ… ìª½ íƒìƒ‰ ê³µê°„ (TrainingArguments) ---\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\":  trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "        \"warmup_ratio\":  trial.suggest_float(\"warmup_ratio\", 0.0, 0.2),\n",
    "        \"lr_scheduler_type\": trial.suggest_categorical(\n",
    "            \"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\"]\n",
    "        ),\n",
    "        # í•„ìš”ì‹œ ë°°ì¹˜/ì—í­ë„ íƒìƒ‰\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [32, 64, 96]),\n",
    "        \"per_device_eval_batch_size\":  trial.suggest_categorical(\"per_device_eval_batch_size\",  [32, 64, 96]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 10, 40),\n",
    "    }\n",
    "\n",
    "# --- 3) ëª©í‘œ ë©”íŠ¸ë¦­ (ì‘ì„ìˆ˜ë¡ ì¢‹ê²Œ) ---\n",
    "def compute_objective(metrics):\n",
    "    # eval_lossë§Œ ìµœì†Œí™”\n",
    "    return metrics[\"eval_loss\"]\n",
    "\n",
    "# --- 4) HPOìš© íŠ¸ë ˆì´ë„ˆ: modelì´ ì•„ë‹ˆë¼ model_initë¥¼ ë„˜ê²¨ì•¼ í•¨! ---\n",
    "trainer_hpo = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,                # ë„¤ ê¸°ì¡´ args (eval_strategy=\"epoch\" ë“± í¬í•¨)\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5, early_stopping_threshold=0.0)],\n",
    ")\n",
    "\n",
    "# --- 5) íƒìƒ‰ ì‹¤í–‰ ---\n",
    "best_run = trainer_hpo.hyperparameter_search(\n",
    "    direction=\"minimize\",\n",
    "    backend=\"optuna\",\n",
    "    n_trials=30,                # ë¦¬ì†ŒìŠ¤ì— ë§ê²Œ ëŠ˜ë¦¬ê¸°/ì¤„ì´ê¸°\n",
    "    hp_space=hp_space,\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True,\n",
    "    compute_objective=compute_objective,\n",
    ")\n",
    "print(\"BEST:\", best_run)\n",
    "print(\"BEST params:\", best_run.hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8fbd6",
   "metadata": {},
   "source": [
    "### ìµœì¢… train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33dd4540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/transformers/training_args.py:2083: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36936' max='36936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36936/36936 48:59, Epoch 38/38]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>1.044818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>1.057113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>1.061777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>1.175085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>1.144505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>1.183083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>1.335289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>1.295056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>1.061753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.584500</td>\n",
       "      <td>1.332420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.998812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>1.707930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.035917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.565400</td>\n",
       "      <td>1.575788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>1.108821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>1.044580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.545600</td>\n",
       "      <td>1.075278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>1.082552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>1.209509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>1.233890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.511200</td>\n",
       "      <td>1.350326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>1.224287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.889255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.860173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>1.091282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.473800</td>\n",
       "      <td>0.823611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>1.261394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>1.338084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>1.031625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>1.233356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.440700</td>\n",
       "      <td>1.141302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>1.130226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>1.146674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.423200</td>\n",
       "      <td>1.174655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.793972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>1.189923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.910126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>1.195237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: ./patchtst_sales_forecast_best/base\n"
     ]
    }
   ],
   "source": [
    "best = best_run.hyperparameters\n",
    "\n",
    "# TrainingArguments ë°˜ì˜\n",
    "\n",
    "args_dict = training_args.to_dict()\n",
    "for k, v in best.items():\n",
    "    if k in args_dict:\n",
    "        args_dict[k] = v\n",
    "best_args = TrainingArguments(**args_dict)\n",
    "\n",
    "def model_init_best():\n",
    "    # best ê°’ìœ¼ë¡œ ë™ì¼í•˜ê²Œ êµ¬ì„±\n",
    "    trial_like = None\n",
    "    # ê·¸ëƒ¥ model_init(None) ì“°ë©´ ê¸°ë³¸ê°’ì´ ë“¤ì–´ê°€ë¯€ë¡œ,\n",
    "    # ì•„ë˜ì²˜ëŸ¼ ì§ì ‘ configë¥¼ ë§Œë“œëŠ” ê²Œ ì•ˆì „. (ê°„ë‹¨íˆëŠ” bestë¥¼ model_initì—ì„œ ì½ë„ë¡ ë°”ê¿”ë„ OK)\n",
    "    patch_length = best[\"patch_length\"]\n",
    "    cfg_best = PatchTSTConfig(\n",
    "        num_input_channels=4,\n",
    "        context_length=context_length,\n",
    "        prediction_length=forecast_horizon,\n",
    "        num_time_varying_known_reals=3,\n",
    "        num_static_categorical_features=1,\n",
    "        cardinality=[num_entities],\n",
    "        embedding_dimension=[32],\n",
    "        d_model=best[\"d_model\"],\n",
    "        num_attention_heads=best[\"num_attention_heads\"],\n",
    "        num_hidden_layers=best[\"num_hidden_layers\"],\n",
    "        ffn_dim=best[\"ffn_dim\"],\n",
    "        dropout=best[\"dropout\"],\n",
    "        head_dropout=best[\"head_dropout\"],\n",
    "        patch_length=patch_length,\n",
    "        patch_stride=patch_length,\n",
    "        scaling=\"std\",\n",
    "        loss=\"mse\",\n",
    "    )\n",
    "\n",
    "    # ì•ˆì „ê°€ë“œ\n",
    "    import math\n",
    "    def _eff(L,p,s): return p * math.ceil(L/s)\n",
    "    assert _eff(cfg_best.context_length, cfg_best.patch_length, cfg_best.patch_stride) == cfg_best.context_length\n",
    "    assert _eff(cfg_best.prediction_length, cfg_best.patch_length, cfg_best.patch_stride) == cfg_best.prediction_length\n",
    "\n",
    "    base = PatchTSTForPrediction(cfg_best)\n",
    "    return PatchTSTSalesOnly(base, target_ch=0)\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model_init=model_init_best,\n",
    "    args=best_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")\n",
    "final_trainer.train()\n",
    "\n",
    "# í›ˆë ¨ ì§í›„\n",
    "SAVE_DIR = \"./patchtst_sales_forecast_best/base\"   # ìƒˆ í´ë”\n",
    "final_trainer.model.base.save_pretrained(SAVE_DIR) # â˜… config.jsonê¹Œì§€ ìƒì„±ë¨\n",
    "print(\"saved to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "366ba0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('learning_rate', 0.00023695284163224964), ('weight_decay', 0.02514135162873802), ('warmup_ratio', 0.05613506650397164), ('lr_scheduler_type', 'polynomial'), ('per_device_train_batch_size', 96), ('per_device_eval_batch_size', 32), ('num_train_epochs', 38), ('d_model', 256), ('num_attention_heads', 8), ('num_hidden_layers', 3), ('ffn_dim', 128), ('dropout', 0.26321548724481086), ('head_dropout', 0.001565806978548051), ('patch_length', 1)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f7cf7",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19be72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def _to_numpy(x):\n",
    "    return x.detach().cpu().numpy() if isinstance(x, torch.Tensor) else x\n",
    "\n",
    "def _pick_pred_array(preds, horizon=forecast_horizon, target_ch=0):\n",
    "    \"\"\"\n",
    "    pred_output.predictionsê°€ tuple/list/dict/object ndarrayì¸ ë‹¤ì–‘í•œ ê²½ìš°ë¥¼ ëª¨ë‘ ì»¤ë²„í•´ì„œ\n",
    "    (N, horizon) í˜•íƒœì˜ sales ì±„ë„ë§Œ êº¼ë‚´ ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    # dict-like\n",
    "    if isinstance(preds, dict):\n",
    "        for k in [\"predictions\", \"logits\", \"prediction_outputs\", \"y_hat\", \"forecast\"]:\n",
    "            if k in preds:\n",
    "                arr = _to_numpy(preds[k])\n",
    "                if isinstance(arr, np.ndarray):\n",
    "                    return arr\n",
    "\n",
    "    # tuple/list\n",
    "    if isinstance(preds, (list, tuple)):\n",
    "        for x in preds:\n",
    "            arr = _to_numpy(x)\n",
    "            if isinstance(arr, np.ndarray) and arr.ndim >= 2:\n",
    "                return arr\n",
    "\n",
    "    # numpy object ë°°ì—´ (ragged)\n",
    "    if isinstance(preds, np.ndarray) and preds.dtype == object:\n",
    "        for x in preds.tolist():\n",
    "            arr = _to_numpy(x)\n",
    "            if isinstance(arr, np.ndarray) and arr.ndim >= 2:\n",
    "                return arr\n",
    "\n",
    "    # ì´ë¯¸ ndarrayì¸ ê²½ìš°\n",
    "    if isinstance(preds, np.ndarray):\n",
    "        return preds\n",
    "\n",
    "    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨\n",
    "    arr = np.asarray(preds, dtype=object)\n",
    "    raise ValueError(f\"ì˜ˆì¸¡ ë°°ì—´ì„ ì¶”ì¶œí•˜ì§€ ëª»í•¨: type={type(preds)}, dtype={getattr(arr,'dtype',None)}\")\n",
    "\n",
    "'''\n",
    "ğŸ·ï¸ ë§¤ì¶œ ì˜ˆì¸¡ì´ë¼ë©´?\n",
    "ì†Œìˆ˜ì  0.5 ê¸°ì¤€ ë°˜ì˜¬ë¦¼ (np.rint) ì´ ê°€ì¥ ë§ì´ ì”ë‹ˆë‹¤.\n",
    "ë‹¤ë§Œ 0.07, 0.08 ê°™ì€ ì‘ì€ ê°’ë“¤ì´ ì‹¤ì œë¡œëŠ” â€œ0ê±´ ë§¤ì¶œâ€ì¸ ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì—, \n",
    "ì„ê³„ê°’(threshold) ê·œì¹™ì„ ì¶”ê°€í•˜ë©´ ë” ì¢‹ì•„ìš”.\n",
    "'''\n",
    "\n",
    "def round_with_threshold(x, threshold=0.3):\n",
    "    if x < threshold:\n",
    "        return 0\n",
    "    return int(np.rint(x))\n",
    "\n",
    "#df_result[\"y_pred_int\"] = df_result[\"y_pred\"].apply(round_with_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edb4fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from: ./patchtst_sales_forecast_best/base\n",
      "Loading model with specified configuration...\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: ./patchtst_sales_forecast_best/base\n",
      "model expects context_length=28, prediction_length=7, num_input_channels=4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import Trainer, AutoConfig\n",
    "from transformers.models.patchtst.modeling_patchtst import PatchTSTForPrediction\n",
    "\n",
    "\n",
    "# 1. í•™ìŠµ ì‹œ TrainingArgumentsì˜ output_dirì— ì €ì¥ëœ 'best' ëª¨ë¸ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "#    ë³´í†µ output_dir ë‚´ë¶€ì— 'checkpoint-...' í˜•íƒœì˜ í´ë”ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "MODEL_PATH = \"./patchtst_sales_forecast_best/base\"\n",
    "\n",
    "# 2. ì €ì¥ëœ ê²½ë¡œì—ì„œ config.jsonì„ ëª…ì‹œì ìœ¼ë¡œ ë¨¼ì € ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "print(f\"Loading configuration from: {MODEL_PATH}\")\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# 3. ìœ„ì—ì„œ ë¶ˆëŸ¬ì˜¨ config ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ì´ë ‡ê²Œ í•˜ë©´ context_length ë“±ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë©ë‹ˆë‹¤.\n",
    "print(\"Loading model with specified configuration...\")\n",
    "model = PatchTSTForPrediction.from_pretrained(MODEL_PATH, config=config)\n",
    "\n",
    "# 3. ì˜ˆì¸¡ ì „ìš© Trainerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "trainer = Trainer(model=model)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}\")\n",
    "\n",
    "# 2) ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ê¸¸ì´ ì½ê¸°\n",
    "CTX = getattr(model.config, \"context_length\", None) or getattr(model.config, \"sequence_length\", None)\n",
    "H   = getattr(model.config, \"prediction_length\", None)\n",
    "print(f\"model expects context_length={CTX}, prediction_length={H}, num_input_channels={model.config.num_input_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32fcd954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_08.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_09.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_02.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_03.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_01.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_00.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_04.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_05.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_07.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_06.csví…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/patch_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ í…Œì´ë¸” shape: (70, 193)\n",
      "store_menu  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_BBQ55(ë‹¨ì²´)  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 30,000ì›  \\\n",
      "ì˜ì—…ì¼ì                                                                           \n",
      "TEST_00+1ì¼            2.559033              0.000000                2.372706   \n",
      "TEST_00+2ì¼            0.517116              5.649229                0.497532   \n",
      "TEST_00+3ì¼            0.664444              5.412844                1.356714   \n",
      "TEST_00+4ì¼            1.930346              9.347913                3.545258   \n",
      "TEST_00+5ì¼            2.594114             55.577057                2.230829   \n",
      "TEST_00+6ì¼            2.424382             38.097389                3.598119   \n",
      "TEST_00+7ì¼           11.727306              1.440253                9.584322   \n",
      "\n",
      "store_menu  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 60,000ì›  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ëŒ€ì—¬ë£Œ 90,000ì›  \\\n",
      "ì˜ì—…ì¼ì                                                         \n",
      "TEST_00+1ì¼                2.034217                0.888842   \n",
      "TEST_00+2ì¼                0.474618                0.133644   \n",
      "TEST_00+3ì¼                0.672966                0.421416   \n",
      "TEST_00+4ì¼                1.511304                0.417181   \n",
      "TEST_00+5ì¼                1.385646                0.409430   \n",
      "TEST_00+6ì¼                1.936102                1.313501   \n",
      "TEST_00+7ì¼                4.762624                3.043181   \n",
      "\n",
      "store_menu  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ë³¸ì‚¼ê²¹ (ë‹¨í’ˆ,ì‹¤ë‚´)  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŠ¤í”„ë¼ì´íŠ¸ (ë‹¨ì²´)  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ì‹ ë¼ë©´  \\\n",
      "ì˜ì—…ì¼ì                                                                        \n",
      "TEST_00+1ì¼                0.306370               0.000000        0.404690   \n",
      "TEST_00+2ì¼                0.227720               6.509136        0.415481   \n",
      "TEST_00+3ì¼                0.418728               3.572153        0.086498   \n",
      "TEST_00+4ì¼                1.112467               3.841885        0.398326   \n",
      "TEST_00+5ì¼                1.837977              12.631332        1.119472   \n",
      "TEST_00+6ì¼                1.259367               5.326182        3.164272   \n",
      "TEST_00+7ì¼                1.598221               0.601897        1.969041   \n",
      "\n",
      "store_menu  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì•¼ì±„ì„¸íŠ¸  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_ìŒˆì¥  ...  í™”ë‹´ìˆ²ì£¼ë§‰_ìŠ¤í”„ë¼ì´íŠ¸  í™”ë‹´ìˆ²ì£¼ë§‰_ì°¸ì‚´ì´ ë§‰ê±¸ë¦¬  \\\n",
      "ì˜ì—…ì¼ì                                         ...                               \n",
      "TEST_00+1ì¼          0.540813       0.239975  ...     1.831903      10.650504   \n",
      "TEST_00+2ì¼          0.000000       0.058137  ...     0.355717       1.885139   \n",
      "TEST_00+3ì¼          0.277300       0.339719  ...     0.807747       1.933617   \n",
      "TEST_00+4ì¼          1.014485       0.232238  ...     1.070008       6.904673   \n",
      "TEST_00+5ì¼          0.577576       0.084932  ...     0.869194       6.680815   \n",
      "TEST_00+6ì¼          0.579072       0.166093  ...     1.316438       4.367537   \n",
      "TEST_00+7ì¼          2.623341       0.746901  ...     3.870981      10.060808   \n",
      "\n",
      "store_menu  í™”ë‹´ìˆ²ì£¼ë§‰_ì°¹ìŒ€ì‹í˜œ  í™”ë‹´ìˆ²ì£¼ë§‰_ì½œë¼  í™”ë‹´ìˆ²ì£¼ë§‰_í•´ë¬¼íŒŒì „  í™”ë‹´ìˆ²ì¹´í˜_ë©”ë°€ë¯¸ìˆ«ê°€ë£¨  í™”ë‹´ìˆ²ì¹´í˜_ì•„ë©”ë¦¬ì¹´ë…¸ HOT  \\\n",
      "ì˜ì—…ì¼ì                                                                          \n",
      "TEST_00+1ì¼    6.099362  3.656293   16.244289     12.957857         3.854789   \n",
      "TEST_00+2ì¼    0.780420  0.186655    4.573645      2.998533         1.354673   \n",
      "TEST_00+3ì¼    1.125971  0.255882    6.240305      3.703561         2.057096   \n",
      "TEST_00+4ì¼    4.337667  1.806404   17.673687     13.305984         4.206266   \n",
      "TEST_00+5ì¼    4.803226  2.214626   17.429842     11.500544         4.061290   \n",
      "TEST_00+6ì¼    4.374877  1.191573   19.172665     12.039627         3.786073   \n",
      "TEST_00+7ì¼   16.216448  5.508526   51.914303     43.919373         9.520521   \n",
      "\n",
      "store_menu  í™”ë‹´ìˆ²ì¹´í˜_ì•„ë©”ë¦¬ì¹´ë…¸ ICE  í™”ë‹´ìˆ²ì¹´í˜_ì¹´í˜ë¼ë–¼ ICE  í™”ë‹´ìˆ²ì¹´í˜_í˜„ë¯¸ë»¥ìŠ¤í¬ë¦¼  \n",
      "ì˜ì—…ì¼ì                                                       \n",
      "TEST_00+1ì¼         9.472677        3.158479      9.866786  \n",
      "TEST_00+2ì¼         3.351847        0.975623      1.515595  \n",
      "TEST_00+3ì¼         5.375538        2.268822      1.663101  \n",
      "TEST_00+4ì¼        13.272474        4.232048      7.567091  \n",
      "TEST_00+5ì¼        10.788205        3.564316      8.515462  \n",
      "TEST_00+6ì¼        14.164421        3.375861      4.409040  \n",
      "TEST_00+7ì¼        41.954285        9.996902     15.385475  \n",
      "\n",
      "[7 rows x 193 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./dataset/test\"\n",
    "files = os.listdir(path)\n",
    "rows = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    test_df = pd.read_csv(os.path.join(path, file))\n",
    "    test_df.columns = [\"date\", \"store_menu\", \"sales\"]\n",
    "    test_df[\"date\"] = pd.to_datetime(test_df[\"date\"])\n",
    "\n",
    "    test_df.loc[test_df['sales'] < 0, 'sales'] = 0\n",
    "    test_df[\"sales\"] = test_df[\"sales\"].astype(float)\n",
    "    test_df[\"sales_log\"] = np.log1p(test_df[\"sales\"])     # targetì€ ì´ì œ sales_log\n",
    "\n",
    "    # ê¸°ì¡´ ì¸ì½”ë” ì‚¬ìš© (encoderëŠ” train ë‹¨ê³„ì—ì„œ fitëœ ê±¸ ê·¸ëŒ€ë¡œ ì¨ì•¼ consistency ë³´ì¥)\n",
    "    test_df[\"store_menu_id\"] = encoder.transform(test_df[\"store_menu\"])\n",
    "\n",
    "    # ë™ì¼í•œ feature ìƒì„±\n",
    "    kr_holidays = holidays.KR(years=test_df['date'].dt.year.unique())\n",
    "    test_df[\"is_holiday\"] = test_df[\"date\"].isin(kr_holidays).astype(int)\n",
    "    test_df[\"is_weekend\"] = test_df[\"date\"].dt.day_of_week.isin([5, 6]).astype(int)\n",
    "    test_df[\"is_ski_season\"] = test_df[\"date\"].dt.month.isin([12, 1, 2]).astype(int)\n",
    "\n",
    "    print(f\"{file}í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "    # ==============================================\n",
    "    # 2. ForecastDFDataset ë³€í™˜\n",
    "    # ==============================================\n",
    "    test_dataset = ForecastDFDataset(\n",
    "        test_df,\n",
    "        id_columns=[\"store_menu_id\"],\n",
    "        timestamp_column=\"date\",\n",
    "        target_columns=[\"sales_log\"],\n",
    "        control_columns=[\"is_holiday\", \"is_weekend\", \"is_ski_season\"],\n",
    "        context_length=context_length,\n",
    "        prediction_length=forecast_horizon,\n",
    "    )\n",
    "\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê¸¸ì´:\", len(test_dataset))\n",
    "\n",
    "    # ==============================================\n",
    "    # 3. ì˜ˆì¸¡ ì‹¤í–‰ (ê²¬ê³  ì¶”ì¶œ ë²„ì „)\n",
    "    # ==============================================\n",
    "    pred_output = trainer.predict(test_dataset)\n",
    "    preds_raw = pred_output.predictions  # ì»¨í…Œì´ë„ˆì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "\n",
    "    arr = _pick_pred_array(preds_raw, horizon=forecast_horizon, target_ch=0)\n",
    "\n",
    "    # ---- (N, 7)ë¡œ ì •ê·œí™” ----\n",
    "    if arr.ndim == 3:\n",
    "        # í”í•œ ì¼€ì´ìŠ¤ 1: (N, horizon, C)\n",
    "        if arr.shape[-2] == forecast_horizon:\n",
    "            arr = arr[..., 0]                 # sales ì±„ë„ë§Œ\n",
    "        # í”í•œ ì¼€ì´ìŠ¤ 2: (N, C, horizon)\n",
    "        elif arr.shape[-1] == forecast_horizon:\n",
    "            arr = arr[:, 0, :]                # sales ì±„ë„ë§Œ\n",
    "        # ë°±ì—…: ë‘ ë²ˆì§¸ ì¶•ì´ horizonì´ë©´ 3ë²ˆì§¸ ì¶•ì„ ì˜ë¼ë³¸ë‹¤\n",
    "        elif arr.shape[1] == forecast_horizon:\n",
    "            arr = arr[:, :, 0]\n",
    "        else:\n",
    "            raise ValueError(f\"ì˜ˆìƒ ë°– 3D shape: {arr.shape}\")\n",
    "    elif arr.ndim == 2:\n",
    "        # (horizon, N) ì´ë©´ ì „ì¹˜\n",
    "        if arr.shape[0] == forecast_horizon and arr.shape[1] != forecast_horizon:\n",
    "            arr = arr.T\n",
    "\n",
    "    # ì´ì œ (N, 7)ì´ì–´ì•¼ ì •ìƒ\n",
    "    assert arr.ndim == 2 and arr.shape[1] == forecast_horizon, f\"ì •ê·œí™” ì‹¤íŒ¨: {arr.shape}\"\n",
    "\n",
    "    # ë¡œê·¸ ì—­ë³€í™˜ + ìŒìˆ˜ ë°©ì§€\n",
    "    y_pred_log = arr\n",
    "    y_pred_sales = np.expm1(y_pred_log)\n",
    "    y_pred_sales = np.clip(y_pred_sales, 0, None)\n",
    "\n",
    "    # 7ì¼ ë¯¸ë˜ ë‚ ì§œ\n",
    "    last_date = test_df[\"date\"].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1),\n",
    "                                periods=forecast_horizon)\n",
    "\n",
    "    # ë§¤ì¥ëª… ìˆœì„œ ê³ ì • (id ì •ë ¬)\n",
    "    keys_df = (\n",
    "        test_df.sort_values([\"store_menu_id\", \"date\"])\n",
    "            .drop_duplicates(\"store_menu_id\")[[\"store_menu_id\", \"store_menu\"]]\n",
    "    )\n",
    "    store_names = keys_df[\"store_menu\"].to_numpy()\n",
    "\n",
    "    # N ê²€ì¦\n",
    "    assert y_pred_sales.shape[0] == len(store_names), (\n",
    "        f\"N ë¶ˆì¼ì¹˜: preds={y_pred_sales.shape[0]} vs stores={len(store_names)}\"\n",
    "    )\n",
    "\n",
    "    # ë§¤ì¥Ã—7ì¼ í…Œì´ë¸”\n",
    "    file_name = file.split(\".c\")[0]\n",
    "    for store_name, pred_row in zip(store_names, y_pred_sales):   # pred_row: (7,)\n",
    "        for day_num, (d, yhat) in enumerate(zip(future_dates, pred_row), start=1):\n",
    "            date_str = f\"{file_name}+{day_num}ì¼\"\n",
    "            rows.append({\"date\": date_str, \"store_menu\": store_name, \"y_pred\": float(yhat)})\n",
    "\n",
    "df_result = pd.DataFrame(rows).pivot(index=\"date\", columns=\"store_menu\", values=\"y_pred\")\n",
    "#df_result[\"y_pred_int\"] = df_result[\"y_pred\"].apply(round_with_threshold)  # ê²°ê³¼ ì •ìˆ˜í™”ë¥¼ ì›í•  ê²½ìš° ì‚¬ìš©\n",
    "df_result.index.name = \"ì˜ì—…ì¼ì\"\n",
    "df_result.to_csv(\"test_predictions.csv\", index=True, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"ì˜ˆì¸¡ í…Œì´ë¸” shape:\", df_result.shape)  # (7, ë§¤ì¥ìˆ˜)\n",
    "print(df_result.head(7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364389c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426add21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fce606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6f6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e8dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
